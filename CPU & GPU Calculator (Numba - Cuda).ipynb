{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36fc991b-fb77-4549-b400-efa711044ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first number:  2\n",
      "Enter the second number:  3\n",
      "Enter operation (add, subtract, multiply, divide):  add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Result: 5.0\n",
      "Time taken on CPU: 0.000003 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mosi1\\anaconda3\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Result: 5.0\n",
      "Time taken on GPU: 0.534545 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mosi1\\anaconda3\\Lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Function to perform basic arithmetic operations on CPU\n",
    "def cpu_calculator(a, b, operation):\n",
    "    if operation == 'add':\n",
    "        return a + b\n",
    "    elif operation == 'subtract':\n",
    "        return a - b\n",
    "    elif operation == 'multiply':\n",
    "        return a * b\n",
    "    elif operation == 'divide':\n",
    "        if b != 0:\n",
    "            return a / b\n",
    "        else:\n",
    "            return \"Error: Division by zero\"\n",
    "    else:\n",
    "        return \"Error: Invalid operation\"\n",
    "\n",
    "# Function to perform basic arithmetic operations on GPU\n",
    "@cuda.jit\n",
    "def gpu_calculator(a, b, operation, result):\n",
    "    idx = cuda.grid(1)  # Get the unique thread index\n",
    "    if idx == 0:  # Only one calculation, so we use the first thread\n",
    "        if operation == 0:  # Add\n",
    "            result[0] = a + b\n",
    "        elif operation == 1:  # Subtract\n",
    "            result[0] = a - b\n",
    "        elif operation == 2:  # Multiply\n",
    "            result[0] = a * b\n",
    "        elif operation == 3:  # Divide\n",
    "            if b != 0:\n",
    "                result[0] = a / b\n",
    "            else:\n",
    "                result[0] = np.nan  # Not a number for error handling\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get two numbers and an operation from user input\n",
    "    a = float(input(\"Enter the first number: \"))  # First number input\n",
    "    b = float(input(\"Enter the second number: \"))  # Second number input\n",
    "    operation = input(\"Enter operation (add, subtract, multiply, divide): \")  # Operation input\n",
    "\n",
    "    # Measure execution time for CPU calculation\n",
    "    start = timer()  \n",
    "    cpu_result = cpu_calculator(a, b, operation)  # Perform calculation on CPU\n",
    "    cpu_time = timer() - start  # Calculate time taken for CPU\n",
    "\n",
    "    # Print results for CPU calculation\n",
    "    print(f\"CPU Result: {cpu_result}\")\n",
    "    print(f\"Time taken on CPU: {cpu_time:.6f} seconds\")  \n",
    "\n",
    "    # Prepare to perform calculation on GPU\n",
    "    # Convert inputs to numpy arrays for GPU\n",
    "    a_device = np.array([a], dtype=np.float64)  # Create a single-element array for first input\n",
    "    b_device = np.array([b], dtype=np.float64)  # Create a single-element array for second input\n",
    "    result_device = np.zeros(1, dtype=np.float64)  # Create an array to store the result on GPU\n",
    "\n",
    "    # Map operations to integers\n",
    "    operations_map = {'add': 0, 'subtract': 1, 'multiply': 2, 'divide': 3}\n",
    "    operation_code = operations_map.get(operation)\n",
    "\n",
    "    if operation_code is None:\n",
    "        print(\"Error: Invalid operation entered for GPU.\")\n",
    "    else:\n",
    "        # Measure execution time for GPU calculation\n",
    "        start = timer()  \n",
    "        # Launch the GPU kernel\n",
    "        gpu_calculator[1, 1](a_device[0], b_device[0], operation_code, result_device)  \n",
    "        cuda.synchronize()  # Wait for the GPU to finish\n",
    "        gpu_time = timer() - start  # Calculate time taken for GPU\n",
    "\n",
    "        # Print results for GPU calculation\n",
    "        gpu_result = result_device[0]  # Get the result from the GPU\n",
    "        if np.isnan(gpu_result):\n",
    "            print(\"GPU Result: Error: Division by zero\")  \n",
    "        else:\n",
    "            print(f\"GPU Result: {gpu_result}\")\n",
    "        print(f\"Time taken on GPU: {gpu_time:.6f} seconds\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248fdc90-c366-4ebc-9e1c-af6750c1eaae",
   "metadata": {},
   "source": [
    "# Why GPU time > CPU time?\n",
    "\n",
    "\n",
    "### 1- Overhead of Data Transfer:\n",
    "\n",
    "#####    When using GPU computations, there is usually a significant overhead due to the need to transfer data between the CPU (host) memory and the GPU (device) memory. In your example, you're performing a calculation on just two numbers, which means the overhead of transferring the data to the GPU and back can outweigh any benefits you gain from the parallel processing capabilities of the GPU.\n",
    "\n",
    "### 2- Kernel Launch Overhead:\n",
    "\n",
    "#####    Starting a GPU kernel involves some overhead. This includes setting up the execution configuration (grid and block sizes), compiling the kernel code if running for the first time, and managing the GPUâ€™s execution. For very simple tasks, this overhead can take longer than performing the calculation on the CPU.\n",
    "\n",
    "### 3- Underutilization of GPU Resources:\n",
    "\n",
    "#####    As noted in the warnings you received, launching only a single thread (or a very small number) to handle operations means you are not leveraging the full capability of the GPU. GPUs are optimized for highly parallel workloads, and launching kernels with a small number of threads leads to low occupancy and increased relative execution time.\n",
    "\n",
    "### 4- Nature of the Calculation:\n",
    "\n",
    "#####    The arithmetic operations on just two numbers are very lightweight tasks. The CPU is already optimized for such small calculations and can handle them with minimal latency. For a more substantial workload, such as operations on large arrays, the GPU typically shows its strength.\n",
    "\n",
    "### 5- Latency in Execution:\n",
    "\n",
    "#####    For small tasks, the latency involved in sending data to the GPU, initiating the computation, and retrieving the results can be higher than just performing the computation directly on the CPU.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
